# nn-cheatsheet
*cheatsheet notebooks for neural network emulator best practices*

in this repo I'll go over the stuff I've learned from a year or two of trial and error in training neural networks - pimarily this is a set of examples of neural network 'best practices'.

we'll look at a couple things:
- loading in data and the choices of scaling
- instantiating a grid search of architectures and hyperparameters in a clean way (not necessarily an optimal way!)
- naming conventions to avoid overwriting models and aiding comparison between architectures late on
- ways to save networks to make sure we have the best performing models in the case of overfitting
- any other stuff I forgot about when writing the readme
